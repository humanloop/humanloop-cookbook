{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b81e0e5be92583",
   "metadata": {},
   "source": [
    "# Humanloop RAG Evaluation Walkthrough\n",
    "The goal of this notebook is to demonstrate how to take an existing RAG pipeline and integrate Humanloop in order to:\n",
    "1. Setup logging for both your [Prompt](https://humanloop.com/docs/v5/concepts/prompts) and retriever [Tool](https://humanloop.com/docs/v5/concepts/prompts) so that you can easily track the versions of these components.\n",
    "2. Create a [Dataset](https://humanloop.com/docs/v5/concepts/prompts) and run Evaluations to benchmark the performance of your RAG pipeline.\n",
    "3. Configure [Evaluators](https://humanloop.com/docs/v5/concepts/evaluators) for monitoring your RAG pipeline in production.\n",
    "\n",
    "\n",
    "## What is Humanloop?\n",
    "Humanloop is an interactive development environment designed to streamline the entire lifecycle of LLM app development. It serves as a central hub where AI, Product, and Engineering teams can collaborate on Prompt management, Evaluation and Monitoring workflows. \n",
    "\n",
    "\n",
    "## What is RAG?\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "- **Retrieval** - Getting the relevant information from a larger data source for a given a query.\n",
    "- **Augmented** - Using the retrieved information as input to an LLM.\n",
    "- **Generation** - Generating an output from the model given the input.\n",
    "\n",
    "In practise, it remains an effective way to exploit LLMs for things like question answering, summarization, and more, where the data source is too large to fit in the context window of the LLM, or where providing the full data source for each query is not cost-effective.\n",
    "\n",
    "\n",
    "## What are the major challenges with RAG?\n",
    "Implementing RAG and other similar flows complicates the process of [Prompt Engineering](https://humanloop.com/blog/prompt-engineering-101) because you expand the design space of your application. There are lots of choices you need to make around the retrieval and Prompt components that can significantly impact the performance of your overall application. For example,\n",
    "- How do you select the data source?\n",
    "- How should it be chunked up and indexed?\n",
    "- What embedding and retrieval model should you use?\n",
    "- How should you combine the retrieved information with the query?\n",
    "- What should your system Prompt be? \n",
    "- Which model should you use?\n",
    "- What should your system message be?\n",
    "etc...\n",
    "\n",
    "The process of versioning, evaluating and monitoring your pipeline therefore needs to consider both the retrieval and generation components. This is where Humanloop can help.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a5f234d7bac09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53965cd45425bab5",
   "metadata": {},
   "source": [
    "# Example RAG Pipeline\n",
    "\n",
    "We first need a reference RAG implementation. Our use case will be Q&A over a corpus of medical documents.\n",
    "\n",
    "### Dataset\n",
    "We will use a version of the [MedQA dataset](https://huggingface.co/datasets/bigbio/med_qa) from Hugging Face. This is a multiple choice question answering problem based on the United States Medical License Exams (USMLE), with reference text books that contain the required information to answer the questions.\n",
    "\n",
    "### Retriever\n",
    "We're going to use [Chroma](https://docs.trychroma.com/getting-started) as a simple local vector DB with their default embedding model ``. You can replace this with your favorite retrieval system.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da007e8494c60446",
   "metadata": {},
   "source": "## Configure pre-requisites"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3e3f74731b50ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:20:18.947373Z",
     "start_time": "2024-08-21T11:20:14.779075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - \u001B[36mchromadb\u001B[39m\n",
      "  - \u001B[36mopenai\u001B[39m\n",
      "  - \u001B[36mpandas\u001B[39m\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Using version \u001B[39;1m^17.0.0\u001B[39;22m for \u001B[36mpyarrow\u001B[39m\n",
      "\n",
      "\u001B[34mUpdating dependencies\u001B[39m\n",
      "\u001B[2K\u001B[34mResolving dependencies...\u001B[39m \u001B[39;2m(1.1s)\u001B[39;22m\n",
      "\n",
      "\u001B[39;1mPackage operations\u001B[39;22m: \u001B[34m1\u001B[39m install, \u001B[34m0\u001B[39m updates, \u001B[34m0\u001B[39m removals\n",
      "\n",
      "  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mPending...\u001B[39m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m0%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m10%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m20%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m30%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m40%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m50%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m60%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m70%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m80%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m90%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mDownloading...\u001B[39m \u001B[39;1m100%\u001B[39;22m\n",
      "\u001B[1A\u001B[0J  \u001B[34;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[39;1m17.0.0\u001B[39;22m\u001B[39m)\u001B[39m: \u001B[34mInstalling...\u001B[39m\n",
      "\u001B[1A\u001B[0J  \u001B[32;1m-\u001B[39;22m \u001B[39mInstalling \u001B[39m\u001B[36mpyarrow\u001B[39m\u001B[39m (\u001B[39m\u001B[32m17.0.0\u001B[39m\u001B[39m)\u001B[39m\n",
      "\n",
      "\u001B[34mWriting lock file\u001B[39m\n"
     ]
    }
   ],
   "source": [
    "!poetry add chromadb openai humanloop==0.8.0b6 pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d1bf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy_Gray_0</td>\n",
       "      <td>Anatomy_Gray</td>\n",
       "      <td>What is anatomy? Anatomy includes those struct...</td>\n",
       "      <td>Anatomy_Gray. What is anatomy? Anatomy include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anatomy_Gray_1</td>\n",
       "      <td>Anatomy_Gray</td>\n",
       "      <td>Observation and visualization are the primary ...</td>\n",
       "      <td>Anatomy_Gray. Observation and visualization ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anatomy_Gray_2</td>\n",
       "      <td>Anatomy_Gray</td>\n",
       "      <td>How can gross anatomy be studied? The term ana...</td>\n",
       "      <td>Anatomy_Gray. How can gross anatomy be studied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anatomy_Gray_3</td>\n",
       "      <td>Anatomy_Gray</td>\n",
       "      <td>This includes the vasculature, the nerves, the...</td>\n",
       "      <td>Anatomy_Gray. This includes the vasculature, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anatomy_Gray_4</td>\n",
       "      <td>Anatomy_Gray</td>\n",
       "      <td>Each of these approaches has benefits and defi...</td>\n",
       "      <td>Anatomy_Gray. Each of these approaches has ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125842</th>\n",
       "      <td>Surgery_Schwartz_14344</td>\n",
       "      <td>Surgery_Schwartz</td>\n",
       "      <td>feedback. However, the evidence base upon whic...</td>\n",
       "      <td>Surgery_Schwartz. feedback. However, the evide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125843</th>\n",
       "      <td>Surgery_Schwartz_14345</td>\n",
       "      <td>Surgery_Schwartz</td>\n",
       "      <td>College of Physicians Council of Associates; F...</td>\n",
       "      <td>Surgery_Schwartz. College of Physicians Counci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125844</th>\n",
       "      <td>Surgery_Schwartz_14346</td>\n",
       "      <td>Surgery_Schwartz</td>\n",
       "      <td>This review of 10 articles published between 2...</td>\n",
       "      <td>Surgery_Schwartz. This review of 10 articles p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125845</th>\n",
       "      <td>Surgery_Schwartz_14347</td>\n",
       "      <td>Surgery_Schwartz</td>\n",
       "      <td>a systematic review. J Surg Educ. 2015;72(6):1...</td>\n",
       "      <td>Surgery_Schwartz. a systematic review. J Surg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125846</th>\n",
       "      <td>Surgery_Schwartz_14348</td>\n",
       "      <td>Surgery_Schwartz</td>\n",
       "      <td>by a faculty member scored higher on a vali-da...</td>\n",
       "      <td>Surgery_Schwartz. by a faculty member scored h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125847 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id             title  \\\n",
       "0               Anatomy_Gray_0      Anatomy_Gray   \n",
       "1               Anatomy_Gray_1      Anatomy_Gray   \n",
       "2               Anatomy_Gray_2      Anatomy_Gray   \n",
       "3               Anatomy_Gray_3      Anatomy_Gray   \n",
       "4               Anatomy_Gray_4      Anatomy_Gray   \n",
       "...                        ...               ...   \n",
       "125842  Surgery_Schwartz_14344  Surgery_Schwartz   \n",
       "125843  Surgery_Schwartz_14345  Surgery_Schwartz   \n",
       "125844  Surgery_Schwartz_14346  Surgery_Schwartz   \n",
       "125845  Surgery_Schwartz_14347  Surgery_Schwartz   \n",
       "125846  Surgery_Schwartz_14348  Surgery_Schwartz   \n",
       "\n",
       "                                                  content  \\\n",
       "0       What is anatomy? Anatomy includes those struct...   \n",
       "1       Observation and visualization are the primary ...   \n",
       "2       How can gross anatomy be studied? The term ana...   \n",
       "3       This includes the vasculature, the nerves, the...   \n",
       "4       Each of these approaches has benefits and defi...   \n",
       "...                                                   ...   \n",
       "125842  feedback. However, the evidence base upon whic...   \n",
       "125843  College of Physicians Council of Associates; F...   \n",
       "125844  This review of 10 articles published between 2...   \n",
       "125845  a systematic review. J Surg Educ. 2015;72(6):1...   \n",
       "125846  by a faculty member scored higher on a vali-da...   \n",
       "\n",
       "                                                 contents  \n",
       "0       Anatomy_Gray. What is anatomy? Anatomy include...  \n",
       "1       Anatomy_Gray. Observation and visualization ar...  \n",
       "2       Anatomy_Gray. How can gross anatomy be studied...  \n",
       "3       Anatomy_Gray. This includes the vasculature, t...  \n",
       "4       Anatomy_Gray. Each of these approaches has ben...  \n",
       "...                                                   ...  \n",
       "125842  Surgery_Schwartz. feedback. However, the evide...  \n",
       "125843  Surgery_Schwartz. College of Physicians Counci...  \n",
       "125844  Surgery_Schwartz. This review of 10 articles p...  \n",
       "125845  Surgery_Schwartz. a systematic review. J Surg ...  \n",
       "125846  Surgery_Schwartz. by a faculty member scored h...  \n",
       "\n",
       "[125847 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47ac94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dependencies for reference implementation\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from chromadb import chromadb\n",
    "from openai import OpenAI\n",
    "from humanloop import Humanloop\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# init clients\n",
    "chroma = chromadb.Client()\n",
    "openai = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"))\n",
    "humanloop = Humanloop(\n",
    "    api_key=os.getenv(\"HUMANLOOP_KEY\"), base_url=os.getenv(\"HUMANLOOP_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c5158d1d159535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:25:30.238654Z",
     "start_time": "2024-08-21T11:25:29.934053Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m knowledge_base \u001B[38;5;241m=\u001B[39m knowledge_base\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;241m1000\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Add to Chroma - will by default use local vector DB and model all-MiniLM-L6-v2\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m \u001B[43mcollection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknowledge_base\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontents\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknowledge_base\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/api/models/Collection.py:80\u001B[0m, in \u001B[0;36mCollection.add\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd\u001B[39m(\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     42\u001B[0m     ids: OneOrMany[ID],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     52\u001B[0m     uris: Optional[OneOrMany[URI]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     53\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Add embeddings to the data store.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m        ids: The ids of the embeddings you wish to add\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     72\u001B[0m \n\u001B[1;32m     73\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     (\n\u001B[1;32m     75\u001B[0m         ids,\n\u001B[1;32m     76\u001B[0m         embeddings,\n\u001B[1;32m     77\u001B[0m         metadatas,\n\u001B[1;32m     78\u001B[0m         documents,\n\u001B[1;32m     79\u001B[0m         uris,\n\u001B[0;32m---> 80\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_and_prepare_embedding_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39m_add(ids, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid, embeddings, metadatas, documents, uris)\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:279\u001B[0m, in \u001B[0;36mCollectionCommon._validate_and_prepare_embedding_set\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m embeddings \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;66;03m# At this point, we know that one of documents or images are provided from the validation above\u001B[39;00m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m documents \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 279\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocuments\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m images \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mimages)\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:568\u001B[0m, in \u001B[0;36mCollectionCommon._embed\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    565\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must provide an embedding function to compute embeddings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    566\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.trychroma.com/guides/embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    567\u001B[0m     )\n\u001B[0;32m--> 568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/api/types.py:211\u001B[0m, in \u001B[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m: EmbeddingFunction[D], \u001B[38;5;28minput\u001B[39m: D) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Embeddings:\n\u001B[0;32m--> 211\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py:200\u001B[0m, in \u001B[0;36mONNXMiniLM_L6_V2.__call__\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Documents) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Embeddings:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;66;03m# Only download the model when it is actually used\u001B[39;00m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download_model_if_not_exists()\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Embeddings, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py:143\u001B[0m, in \u001B[0;36mONNXMiniLM_L6_V2._forward\u001B[0;34m(self, documents, batch_size)\u001B[0m\n\u001B[1;32m    134\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([e\u001B[38;5;241m.\u001B[39mattention_mask \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m encoded])\n\u001B[1;32m    135\u001B[0m onnx_input \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39marray(input_ids, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint64),\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39marray(attention_mask, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint64),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    141\u001B[0m     ),\n\u001B[1;32m    142\u001B[0m }\n\u001B[0;32m--> 143\u001B[0m model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monnx_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m model_output[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    145\u001B[0m \u001B[38;5;66;03m# Perform mean pooling with attention weighting\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    218\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# init collection into which we will add documents\n",
    "collection = chroma.get_or_create_collection(name=\"MedQA\")\n",
    "\n",
    "# load knowledge base\n",
    "knowledge_base = pd.read_parquet(\"../../assets/sources/textbooks.parquet\")\n",
    "knowledge_base = knowledge_base.sample(1000, random_state=42)\n",
    "\n",
    "\n",
    "# Add to Chroma - will by default use local vector DB and model all-MiniLM-L6-v2\n",
    "collection.add(\n",
    "    documents=knowledge_base[\"contents\"].to_list(),\n",
    "    ids=knowledge_base[\"id\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "187af8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "temperature = 0\n",
    "template = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Answer the following question factually.\n",
    "\n",
    "Question: {{question}}\n",
    "\n",
    "Options:\n",
    "- {{option_A}}\n",
    "- {{option_B}}\n",
    "- {{option_C}}\n",
    "- {{option_D}}\n",
    "- {{option_E}}\n",
    "\n",
    "---\n",
    "\n",
    "Here is some retrieved information that might be helpful.\n",
    "Retrieved data:\n",
    "{{retrieved_data}}\n",
    "\n",
    "---\n",
    "\n",
    "Give you answer in 3 sections using the following format. Do not include the quotes or the brackets. Do include the \"---\" separators.\n",
    "```\n",
    "<chosen option verbatim>\n",
    "---\n",
    "<clear explanation of why the option is correct and why the other options are incorrect. keep it ELI5.>\n",
    "---\n",
    "<quote relevant information snippets from the retrieved data verbatim. every line here should be directly copied from the retrieved data>\n",
    "```\n",
    "\"\"\",\n",
    "    }\n",
    "]\n",
    "\n",
    "def populate_template(template: list, inputs: dict[str, str]) -> list:\n",
    "    \"\"\"Populate a template with input variables.\"\"\"\n",
    "    # TODO: Move to utils.\n",
    "    messages = []\n",
    "    for i, template_message in enumerate(template):\n",
    "        content = template_message[\"content\"]\n",
    "        for key, value in inputs.items():\n",
    "            content = content.replace(\"{{\" + key + \"}}\", value)\n",
    "        message = {**template_message, \"content\": content}\n",
    "        messages.append(message)\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53c95ad9790ade59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:28:32.324148Z",
     "start_time": "2024-08-21T11:28:32.319320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reference RAG pipeline using Chroma and OpenAI\n",
    "\n",
    "def retrieval_tool(question: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents using a chroma collection.\"\"\"\n",
    "    response = collection.query(query_texts=[question], n_results=1)\n",
    "    retrieved_doc = response[\"documents\"][0][0]\n",
    "    return retrieved_doc\n",
    "\n",
    "\n",
    "def ask_question(inputs: dict[str, str])-> str:\n",
    "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
    "    retrieved_data = retrieval_tool(inputs[\"question\"])\n",
    "\n",
    "    inputs = {**inputs, \"retrieved_data\": retrieved_data}\n",
    "    messages = populate_template(template, inputs)\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "    )\n",
    "    answer = chat_completion.choices[0].message.content\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da57f2c4b4533a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:28:40.883975Z",
     "start_time": "2024-08-21T11:28:37.778978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "50%\n",
      "---\n",
      "The probability that the second daughter is a carrier of the disease is 50%. This is because the daughters of a male with hemophilia A will either be carriers (50% chance) or unaffected (50% chance), as daughters inherit one X chromosome from their father. The other options are incorrect because the daughters cannot have hemophilia A themselves due to the inheritance pattern of the disease.\n",
      "\n",
      "---\n",
      "\"During meiosis or mitosis, failure of a chromosomal pair to separate properly results in nondisjunction.\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline\n",
    "\n",
    "print(\n",
    "    ask_question(\n",
    "        {\n",
    "            \"question\": \"A 34-year-old male suffers from inherited hemophilia A. He and his wife have three unaffected daughters. What is the probability that the second daughter is a carrier of the disease?\",\n",
    "            'option_A': '0%', 'option_B': '25%', 'option_C': '50%', 'option_D': '75%', 'option_E': '100%'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc3cffe1b5cb99",
   "metadata": {},
   "source": [
    "# Humanloop Integration\n",
    "\n",
    "The steps to the Humanloop integration are as follows:\n",
    "....\n",
    "\n",
    "We demonstrate how you can log to or call any of the core entities on Humanloop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d598fd",
   "metadata": {},
   "source": [
    "Add the appropriate Humanloop \"log\" calls to your code to log the relevant information to Humanloop.\n",
    "\n",
    "Below, we add a `humanloop.tools.log(...)` call after the retrieval step to log the retrieved documents to Humanloop,\n",
    "and a `humanloop.prompts.log(...)` call after the chat completion generation.\n",
    "We also pass in a `session_id` to link these two Logs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "985a6fa7b2f095da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import uuid\n",
    "\n",
    "def retrieval_tool(question: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents using a chroma collection.\"\"\"\n",
    "    response = collection.query(query_texts=[question], n_results=1)\n",
    "    retrieved_doc = response[\"documents\"][0][0]\n",
    "    return retrieved_doc\n",
    "\n",
    "\n",
    "def ask_question(inputs: dict[str, str])-> str:\n",
    "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
    "    retrieved_data = retrieval_tool(inputs[\"question\"])\n",
    "\n",
    "    session_id = uuid.uuid4().hex\n",
    "    humanloop.tools.log(\n",
    "        path=\"evals_demo/medqa-retrieval\",\n",
    "        tool={\n",
    "            \"function\": {\n",
    "                \"name\": \"retrieval_tool\",\n",
    "                \"description\": \"Retrieval tool for MedQA.\",\n",
    "            },\n",
    "            \"source_code\": inspect.getsource(retrieval_tool),\n",
    "        },\n",
    "        output=retrieved_data,\n",
    "        session_id=session_id,\n",
    "    )\n",
    "\n",
    "    inputs = {**inputs, \"retrieved_data\": retrieved_data}\n",
    "    messages = populate_template(template, inputs)\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "    )\n",
    "    answer = chat_completion.choices[0].message.content\n",
    "\n",
    "    humanloop.prompts.log(\n",
    "        path=\"evals_demo/medqa-answer\",\n",
    "        prompt={\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"template\": template,\n",
    "        },\n",
    "        inputs=inputs,\n",
    "        output=chat_completion.choices[0].message.content,\n",
    "        output_message=chat_completion.choices[0].message,\n",
    "        session_id=session_id,\n",
    "    )\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571b0ecf202147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update. This is old.\n",
    "\n",
    "# Manage your Prompt on Humanloop\n",
    "\n",
    "def ask_question(question: str)-> str:\n",
    "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    response = collection.query(query_texts=[\"question\"], n_results=1)\n",
    "    retrieved_doc = response[\"documents\"][0][0]\n",
    "    \n",
    "    # Generate answer using Prompt managed on Humanloop\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": retrieved_doc}\n",
    "        ]\n",
    "    answer = hl.prompt.call(\n",
    "        path=\"faq-bot/rag-prompt\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e5f31dc65ba72",
   "metadata": {},
   "source": [
    "# Setting up Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272f102",
   "metadata": {},
   "source": [
    "## Extend Humanloop integration\n",
    "\n",
    "Add `source_datapoint_id` to the `humanloop.prompt.log(...)` and `humanloop.tool.log(...)` calls.\n",
    "We do this below by adding the optional `datapoint_id` argument to `ask_question(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d208b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import uuid\n",
    "\n",
    "def retrieval_tool(question: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents using a chroma collection.\"\"\"\n",
    "    response = collection.query(query_texts=[question], n_results=1)\n",
    "    retrieved_doc = response[\"documents\"][0][0]\n",
    "    return retrieved_doc\n",
    "\n",
    "\n",
    "def ask_question(inputs: dict[str, str], datapoint_id: str | None = None)-> str:\n",
    "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
    "    retrieved_data = retrieval_tool(inputs[\"question\"])\n",
    "\n",
    "    session_id = uuid.uuid4().hex\n",
    "    humanloop.tools.log(\n",
    "        path=\"evals_demo/medqa-retrieval\",\n",
    "        tool={\n",
    "            \"function\": {\n",
    "                \"name\": \"retrieval_tool\",\n",
    "                \"description\": \"Retrieval tool for MedQA.\",\n",
    "            },\n",
    "            \"source_code\": inspect.getsource(retrieval_tool),\n",
    "        },\n",
    "        output=retrieved_data,\n",
    "        session_id=session_id,\n",
    "        source_datapoint_id=datapoint_id,\n",
    "    )\n",
    "\n",
    "    inputs = {**inputs, \"retrieved_data\": retrieved_data}\n",
    "    messages = populate_template(template, inputs)\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "    )\n",
    "    answer = chat_completion.choices[0].message.content\n",
    "\n",
    "    humanloop.prompts.log(\n",
    "        path=\"evals_demo/medqa-answer\",\n",
    "        prompt={\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"template\": template,\n",
    "        },\n",
    "        inputs=inputs,\n",
    "        output=chat_completion.choices[0].message.content,\n",
    "        output_message=chat_completion.choices[0].message,\n",
    "        session_id=session_id,\n",
    "        source_datapoint_id=datapoint_id,\n",
    "    )\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78969c2f",
   "metadata": {},
   "source": [
    "## Creating a dataset\n",
    "- From your existing logs\n",
    "- using the SDK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87c70e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset_to_humanloop(df: pd.DataFrame):\n",
    "    df = pd.read_json(\"../../assets/datapoints.jsonl\", lines=True)\n",
    "\n",
    "    datapoints = [row.to_dict() for _i, row in df.iterrows()]\n",
    "    return humanloop.datasets.upsert(\n",
    "        path=\"evals_demo/medqa-test\",\n",
    "        datapoints=datapoints,\n",
    "        commit_message=f\"Added {len(datapoints)} datapoints from MedQA test dataset.\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deae78c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "status_code: 422, body: detail={'loc': ['commit_message'], 'msg': 'Error creating Version', 'description': \"Version 'dsv_No7Ofzh5RrFPWBbfujGfy' has already been committed.\", 'type': 'invalid_request_error'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnprocessableEntityError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mupload_dataset_to_humanloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[56], line 5\u001B[0m, in \u001B[0;36mupload_dataset_to_humanloop\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_json(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../assets/datapoints.jsonl\u001B[39m\u001B[38;5;124m\"\u001B[39m, lines\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m datapoints \u001B[38;5;241m=\u001B[39m [row\u001B[38;5;241m.\u001B[39mto_dict() \u001B[38;5;28;01mfor\u001B[39;00m _i, row \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39miterrows()]\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhumanloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mevals_demo/medqa-test\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatapoints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatapoints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAdded \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdatapoints\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m datapoints from MedQA test dataset.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/humanloop/datasets/client.py:243\u001B[0m, in \u001B[0;36mDatasetsClient.upsert\u001B[0;34m(self, datapoints, version_id, environment, path, id, action, commit_message, request_options)\u001B[0m\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m typing\u001B[38;5;241m.\u001B[39mcast(DatasetResponse, construct_type(type_\u001B[38;5;241m=\u001B[39mDatasetResponse, object_\u001B[38;5;241m=\u001B[39m_response\u001B[38;5;241m.\u001B[39mjson()))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m422\u001B[39m:\n\u001B[0;32m--> 243\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m UnprocessableEntityError(\n\u001B[1;32m    244\u001B[0m             typing\u001B[38;5;241m.\u001B[39mcast(HttpValidationError, construct_type(type_\u001B[38;5;241m=\u001B[39mHttpValidationError, object_\u001B[38;5;241m=\u001B[39m_response\u001B[38;5;241m.\u001B[39mjson()))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    245\u001B[0m         )\n\u001B[1;32m    246\u001B[0m     _response_json \u001B[38;5;241m=\u001B[39m _response\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError:\n",
      "\u001B[0;31mUnprocessableEntityError\u001B[0m: status_code: 422, body: detail={'loc': ['commit_message'], 'msg': 'Error creating Version', 'description': \"Version 'dsv_No7Ofzh5RrFPWBbfujGfy' has already been committed.\", 'type': 'invalid_request_error'}"
     ]
    }
   ],
   "source": [
    "upload_dataset_to_humanloop(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb5c76",
   "metadata": {},
   "source": [
    "## Set up Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0dcb9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_evaluators():\n",
    "    for evaluator_name, return_type in [\n",
    "        (\"exact_match\", \"boolean\"),\n",
    "        (\"levenshtein\", \"number\"),\n",
    "    ]:\n",
    "        with open(f\"../../assets/evaluators/{evaluator_name}.py\", \"r\") as f:\n",
    "            code = f.read()\n",
    "        humanloop.evaluators.upsert(\n",
    "            path=f\"evals_demo/{evaluator_name}\",\n",
    "            spec={\n",
    "                \"evaluator_type\": \"python\",\n",
    "                \"arguments_type\": \"target_required\",\n",
    "                \"return_type\": return_type,\n",
    "                \"code\": code,\n",
    "            },\n",
    "            commit_message=f\"New version from {evaluator_name}.py\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8138e15d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "status_code: 422, body: detail={'loc': ['commit_message'], 'msg': 'Error creating Version', 'description': \"Version 'evv_w85ulWbWFqElPWxXe3lEu' has already been committed.\", 'type': 'invalid_request_error'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnprocessableEntityError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mupload_evaluators\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[58], line 8\u001B[0m, in \u001B[0;36mupload_evaluators\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../assets/evaluators/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mevaluator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      7\u001B[0m     code \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m----> 8\u001B[0m \u001B[43mhumanloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluators\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mevals_demo/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mevaluator_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mevaluator_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpython\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43marguments_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtarget_required\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreturn_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNew version from \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mevaluator_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/code/humanloop/humanloop-cookbook/venv/lib/python3.11/site-packages/humanloop/evaluators/client.py:208\u001B[0m, in \u001B[0;36mEvaluatorsClient.upsert\u001B[0;34m(self, spec, path, id, commit_message, request_options)\u001B[0m\n\u001B[1;32m    206\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m typing\u001B[38;5;241m.\u001B[39mcast(EvaluatorResponse, construct_type(type_\u001B[38;5;241m=\u001B[39mEvaluatorResponse, object_\u001B[38;5;241m=\u001B[39m_response\u001B[38;5;241m.\u001B[39mjson()))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m422\u001B[39m:\n\u001B[0;32m--> 208\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m UnprocessableEntityError(\n\u001B[1;32m    209\u001B[0m             typing\u001B[38;5;241m.\u001B[39mcast(HttpValidationError, construct_type(type_\u001B[38;5;241m=\u001B[39mHttpValidationError, object_\u001B[38;5;241m=\u001B[39m_response\u001B[38;5;241m.\u001B[39mjson()))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    210\u001B[0m         )\n\u001B[1;32m    211\u001B[0m     _response_json \u001B[38;5;241m=\u001B[39m _response\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError:\n",
      "\u001B[0;31mUnprocessableEntityError\u001B[0m: status_code: 422, body: detail={'loc': ['commit_message'], 'msg': 'Error creating Version', 'description': \"Version 'evv_w85ulWbWFqElPWxXe3lEu' has already been committed.\", 'type': 'invalid_request_error'}"
     ]
    }
   ],
   "source": [
    "upload_evaluators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48f645",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12405c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_evaluation():\n",
    "    \"\"\"Runs an Evaluation.\"\"\"\n",
    "\n",
    "    DATASET_ID = \"ds_\"\n",
    "    DATASET_VERSION_ID = \"dsv_\"\n",
    "    PROMPT_VERSION_ID = \"prv_\"\n",
    "    EVALUATOR_VERSION_IDS = [\n",
    "        \"evv_\",  # exact_match\n",
    "        \"evv_\",  # levenshtein\n",
    "    ]\n",
    "\n",
    "    evaluation = humanloop.evaluations.create(\n",
    "        dataset={\"version_id\": DATASET_VERSION_ID},\n",
    "        evaluatees=[{\"version_id\": PROMPT_VERSION_ID, \"orchestrated\": False}],\n",
    "        evaluators=[{\"version_id\": ev_id} for ev_id in EVALUATOR_VERSION_IDS],\n",
    "    )\n",
    "    print(f\"Evaluation created: {evaluation.id}\")\n",
    "\n",
    "    retrieved_dataset = humanloop.datasets.get(\n",
    "        id=DATASET_ID,\n",
    "        version_id=DATASET_VERSION_ID,\n",
    "        include_datapoints=True,\n",
    "    )\n",
    "    for datapoint in tqdm(retrieved_dataset.datapoints):\n",
    "        # with evaluation(datapoint.id):\n",
    "        ask_question(\n",
    "            inputs=datapoint.inputs,\n",
    "            datapoint_id=datapoint.id,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c951317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation created: evr_tDoZQgxw3ZCSV5EV7HTXy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 53/1273 [03:12<1:10:42,  3.48s/it]"
     ]
    }
   ],
   "source": [
    "run_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
