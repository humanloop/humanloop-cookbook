{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da007e8494c60446",
      "metadata": {},
      "source": [
        "## Complete Prerequisites\n",
        "\n",
        "### Install packages\n",
        "\n",
        "We use poetry to manage dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b3e3f74731b50ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
            "\n",
            "No dependencies to install or update\n",
            "\n",
            "\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mhumanloop-cookbook\u001b[39m (\u001b[39;1m0.1.0\u001b[39;22m)\n",
            "\u001b[33mWarning: The current project could not be installed: No file/folder found for package humanloop-cookbook\n",
            "If you do not want to install the current project use \u001b[39m\u001b[36m--no-root\u001b[39m\u001b[33m.\n",
            "If you want to use Poetry only for dependency management but not for packaging, you can disable package mode by setting \u001b[39m\u001b[36mpackage-mode = false\u001b[39m\u001b[33m in your pyproject.toml file.\n",
            "In a future version of Poetry this warning will become an error!\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!poetry install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80f74709ea0177a8",
      "metadata": {},
      "source": [
        "### Initialise the SDKs\n",
        "\n",
        "You will need to set your OpenAI API key in the `.env` file in the root of the repo. You can retrieve your API key from your [OpenAI account](https://platform.openai.com/api-keys).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "10fabbfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "IS_DEV = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0320f789",
      "metadata": {},
      "outputs": [],
      "source": [
        "HL_KEY = \"\"\n",
        "OPENAI_KEY = \"\"\n",
        "HOST = \"neostaging.humanloop.ml\" if IS_DEV else \"http://0.0.0.0:80\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "47ac94aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up dependencies\n",
        "import os\n",
        "from chromadb import chromadb\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# init clients\n",
        "chroma = chromadb.Client()\n",
        "openai = OpenAI(api_key=OPENAI_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f74ffee245036bc",
      "metadata": {},
      "source": [
        "### Set up the Vector DB\n",
        "\n",
        "This involves loading the data from the MedQA dataset and embedding the data within a collection in Chroma. This will take a couple of minutes to complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "15c5158d1d159535",
      "metadata": {},
      "outputs": [],
      "source": [
        "# init collection into which we will add documents\n",
        "collection = chroma.get_or_create_collection(name=\"MedQA\")\n",
        "\n",
        "# load knowledge base\n",
        "knowledge_base = pd.read_parquet(\"../../assets/sources/textbooks.parquet\")\n",
        "knowledge_base = knowledge_base.sample(5, random_state=42)\n",
        "\n",
        "\n",
        "# Add to Chroma - will by default use local vector DB and model all-MiniLM-L6-v2\n",
        "collection.add(\n",
        "    documents=knowledge_base[\"contents\"].to_list(),\n",
        "    ids=knowledge_base[\"id\"].to_list(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd43484af0f2f10c",
      "metadata": {},
      "source": [
        "### Define the Prompt\n",
        "\n",
        "We define a simple prompt template that has variables for the question, answer options and retrieved data.\n",
        "\n",
        "It is generally good practise to define the Prompt details that impact the behaviour of the model in one place separate to your application logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "187af8c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"gpt-3.5-turbo\"\n",
        "temperature = 0\n",
        "template = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Answer the following question factually.\n",
        "\n",
        "Question: {{question}}\n",
        "\n",
        "Options:\n",
        "- {{option_A}}\n",
        "- {{option_B}}\n",
        "- {{option_C}}\n",
        "- {{option_D}}\n",
        "- {{option_E}}\n",
        "\n",
        "---\n",
        "\n",
        "Here is some retrieved information that might be helpful.\n",
        "Retrieved data:\n",
        "{{retrieved_data}}\n",
        "\n",
        "---\n",
        "\n",
        "Give you answer in 3 sections using the following format. Do not include the quotes or the brackets. Do include the \"---\" separators.\n",
        "```\n",
        "<chosen option verbatim>\n",
        "---\n",
        "<clear explanation of why the option is correct and why the other options are incorrect. keep it ELI5.>\n",
        "---\n",
        "<quote relevant information snippets from the retrieved data verbatim. every line here should be directly copied from the retrieved data>\n",
        "```\n",
        "\"\"\",\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "def populate_template(template: list, inputs: dict[str, str]) -> list:\n",
        "    \"\"\"Populate a template with input variables.\"\"\"\n",
        "    messages = []\n",
        "    for i, template_message in enumerate(template):\n",
        "        content = template_message[\"content\"]\n",
        "        for key, value in inputs.items():\n",
        "            content = content.replace(\"{{\" + key + \"}}\", value)\n",
        "        message = {**template_message, \"content\": content}\n",
        "        messages.append(message)\n",
        "    return messages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86410ee6d885c4b",
      "metadata": {},
      "source": [
        "## Define the RAG Pipeline\n",
        "\n",
        "Now we provide the reference RAG pipeline using Chroma and OpenAI that takes a question and returns an answer. This is ultimately what we will evaluate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "53c95ad9790ade59",
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieval_tool(question: str) -> str:\n",
        "    \"\"\"Retrieve most relevant document from the vector db (Chroma) for the question.\"\"\"\n",
        "    response = collection.query(query_texts=[question], n_results=1)\n",
        "    retrieved_doc = response[\"documents\"][0][0]\n",
        "    return retrieved_doc\n",
        "\n",
        "\n",
        "def ask_question(inputs: dict[str, str]) -> str:\n",
        "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
        "\n",
        "    # Retrieve context\n",
        "    retrieved_data = retrieval_tool(inputs[\"question\"])\n",
        "    inputs = {**inputs, \"retrieved_data\": retrieved_data}\n",
        "\n",
        "    # Populate the Prompt template\n",
        "    messages = populate_template(template, inputs)\n",
        "\n",
        "    # Call OpenAI to get response\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        messages=messages,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "da57f2c4b4533a09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```\n",
            "50%\n",
            "---\n",
            "The probability that the second daughter is a carrier of the disease is 50%. This is because the daughters of a male with hemophilia A will either inherit the disease (if they receive the affected X chromosome) or be carriers (if they receive the normal X chromosome). Since the daughters are unaffected, they must be carriers of the disease.\n",
            "\n",
            "---\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test the pipeline\n",
        "\n",
        "print(\n",
        "    ask_question(\n",
        "        {\n",
        "            \"question\": \"A 34-year-old male suffers from inherited hemophilia A. He and his wife have three unaffected daughters. What is the probability that the second daughter is a carrier of the disease?\",\n",
        "            \"option_A\": \"0%\",\n",
        "            \"option_B\": \"25%\",\n",
        "            \"option_C\": \"50%\",\n",
        "            \"option_D\": \"75%\",\n",
        "            \"option_E\": \"100%\",\n",
        "        }\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fc3cffe1b5cb99",
      "metadata": {},
      "source": [
        "# Humanloop Integration\n",
        "\n",
        "We now integrate Humanloop into the RAG pipeline to first enable logging and then to trigger evaluations against a dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5272f102",
      "metadata": {},
      "source": [
        "## Flow V1 Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d208b64c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import inspect\n",
        "import uuid\n",
        "\n",
        "flow_id = None\n",
        "\n",
        "\n",
        "def ask_question(\n",
        "    inputs: dict[str, str],\n",
        "    datapoint_id: str | None = None,\n",
        "    evaluation_id: str | None = None,\n",
        ") -> str:\n",
        "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
        "    trace_request = requests.post(\n",
        "        f\"{HOST}/v5/flows/log\",\n",
        "        headers={\"X-API-KEY\": HL_KEY},\n",
        "        json={\n",
        "            \"log_id\": uuid.uuid4().hex,\n",
        "            \"flow\": {\n",
        "                \"attributes\": {\n",
        "                    \"description\": \"Answering medical questions\",\n",
        "                    \"chroma\": 1,\n",
        "                }\n",
        "            },\n",
        "            \"path\": \"evals_demo/medqa-flow\",\n",
        "            \"source_datapoint_id\": datapoint_id,\n",
        "            \"evaluation_id\": evaluation_id,\n",
        "        },\n",
        "    ).json()\n",
        "    print(trace_request)\n",
        "    trace_id = trace_request[\"id\"]\n",
        "\n",
        "    try:\n",
        "        flow_id = trace_request[\"flow_id\"]\n",
        "\n",
        "        # Create an Evaluator to count the number of children in the trace\n",
        "        with open(\"../../assets/evaluators/count_trace_children.py\", \"r\") as fp:\n",
        "            code = fp.read()\n",
        "\n",
        "        evaluator_response = requests.post(\n",
        "            f\"{HOST}/v5/evaluators\",\n",
        "            headers={\"X-API-KEY\": HL_KEY},\n",
        "            json={\n",
        "                \"spec\": {\n",
        "                    \"code\": code,\n",
        "                    \"evaluator_type\": \"python\",\n",
        "                    \"return_type\": \"number\",\n",
        "                    \"arguments_type\": \"target_free\",\n",
        "                },\n",
        "                \"path\": \"evals_demo/count-trace-children\",\n",
        "            },\n",
        "        )\n",
        "        # Associate trace_children evaluator with the Flow\n",
        "        ev_version_id: int = evaluator_response.json()[\"version_id\"]\n",
        "        requests.post(\n",
        "            f\"{HOST}/v5/flows/{flow_id}/evaluators\",\n",
        "            headers={\"X-API-KEY\": HL_KEY},\n",
        "            json={\n",
        "                \"activate\": [\n",
        "                    {\n",
        "                        \"evaluator_version_id\": ev_version_id,\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "        )\n",
        "    except:  # noqa: E722\n",
        "        # Evaluator already exists\n",
        "        pass\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    # Retrieve context\n",
        "    retrieved_data = retrieval_tool(inputs[\"question\"])\n",
        "\n",
        "    end_time = datetime.datetime.now()\n",
        "\n",
        "    # Log the context and retriever details to your Humanloop Tool\n",
        "    requests.post(\n",
        "        f\"{HOST}/v5/tools/log\",\n",
        "        json={\n",
        "            \"path\": \"evals_demo/medqa-retrieval\",\n",
        "            \"tool\": {\n",
        "                \"function\": {\n",
        "                    \"name\": \"retrieval_tool\",\n",
        "                    \"description\": \"Retrieval tool for MedQA.\",\n",
        "                },\n",
        "                \"source_code\": inspect.getsource(retrieval_tool),\n",
        "            },\n",
        "            \"output\": retrieved_data,\n",
        "            \"trace_parent_id\": trace_id,\n",
        "            \"start_time\": start_time.isoformat(),\n",
        "            \"end_time\": end_time.isoformat(),\n",
        "        },\n",
        "        headers={\"X-API-Key\": HL_KEY},\n",
        "    )\n",
        "\n",
        "    # Populate the Prompt template\n",
        "    inputs = {**inputs, \"retrieved_data\": retrieved_data}\n",
        "    messages = populate_template(template, inputs)\n",
        "\n",
        "    # Call OpenAI to get a response\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        messages=messages,\n",
        "    )\n",
        "    message = chat_completion.choices[0].message\n",
        "    answer = message.content\n",
        "\n",
        "    end_time = datetime.datetime.now()\n",
        "\n",
        "    requests.post(\n",
        "        f\"{HOST}/v5/prompts/log\",\n",
        "        headers={\"X-API-Key\": HL_KEY},\n",
        "        json={\n",
        "            \"path\": \"evals_demo/medqa-answer\",\n",
        "            \"prompt\": {\n",
        "                \"model\": model,\n",
        "                \"temperature\": temperature,\n",
        "                \"template\": template,\n",
        "            },\n",
        "            \"inputs\": inputs,\n",
        "            \"output\": answer,\n",
        "            \"output_message\": message.to_dict(),\n",
        "            \"trace_parent_id\": trace_id,\n",
        "            \"source_datapoint_id\": datapoint_id,\n",
        "            \"evaluation_id\": evaluation_id,\n",
        "            \"start_time\": start_time.isoformat(),\n",
        "            \"end_time\": end_time.isoformat(),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        requests.patch(\n",
        "            f\"{HOST}/v5/flows/logs/{trace_id}\",\n",
        "            headers={\"X-API-KEY\": HL_KEY},\n",
        "            json={\n",
        "                \"inputs\": inputs,\n",
        "                \"output\": answer,\n",
        "                \"trace_status\": \"complete\",\n",
        "            },\n",
        "            timeout=2,\n",
        "        )\n",
        "    except Exception as e:  # noqa: E722\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78969c2f",
      "metadata": {},
      "source": [
        "## Create a Dataset\n",
        "\n",
        "Here we will create a Dataset on Humanloop using the MedQA test dataset. Alternatively you can create a data from Logs on Humanloop, or upload via the UI - see our [guide](https://humanloop.com/docs/v5/evaluation/guides/create-dataset).\n",
        "\n",
        "You can then effectively version control your Dataset centrally on Humanloop and hook into it for Evaluation workflows in code and via the UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "87c70e0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_dataset_to_humanloop():\n",
        "    df = pd.read_json(\"../../assets/datapoints.jsonl\", lines=True)\n",
        "\n",
        "    datapoints = [row.to_dict() for _i, row in df.iterrows()][0:20]\n",
        "\n",
        "    response = requests.post(\n",
        "        f\"{HOST}/v5/datasets\",\n",
        "        json={\n",
        "            \"path\": \"evals_demo/medqa-test\",\n",
        "            \"commit_message\": f\"Added {len(datapoints)} datapoints from MedQA test dataset.\",\n",
        "            \"datapoints\": datapoints,\n",
        "        },\n",
        "        headers={\"X-API-Key\": HL_KEY},\n",
        "    )\n",
        "    print(response.json())\n",
        "    return response.json()[\"id\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "deae78c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'path': 'evals_demo/medqa-test', 'id': 'ds_JHjdcy1Pwn6ZxAnDglU30', 'directory_id': 'dir_7pYI47Zq55Ytx7eDyuYDo', 'name': 'medqa-test', 'version_id': 'dsv_8E2y5YjQt9Y9Y4Ni1DTvY', 'type': 'dataset', 'environments': [{'id': 'env_NakuPkQXr8w4dYkTAAynO', 'created_at': '2024-04-29T08:01:19.415384', 'name': 'production', 'tag': 'default'}], 'created_at': '2024-10-04T13:18:52.708228', 'updated_at': '2024-10-04T13:18:52.708228', 'created_by': {'id': 'usr_mp3w0ne3k8cwCh3IdyqQJ', 'email_address': 'andrei@humanloop.com', 'full_name': 'Andrei Bratu', 'platform_access': 'user'}, 'status': 'committed', 'last_used_at': '2024-10-04T13:18:52.708228', 'commit_message': 'Added 20 datapoints from MedQA test dataset.', 'datapoints_count': 20, 'datapoints': None, 'team_id': 'tm_b79syTwUvFjr0T1tmT8wq', 'attributes': None}\n"
          ]
        }
      ],
      "source": [
        "dataset_id = upload_dataset_to_humanloop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ffb5c76",
      "metadata": {},
      "source": [
        "## Set up Evaluators\n",
        "\n",
        "Here we will upload some Evaluators defined in code in `assets/evaluators/` so that Humanloop can manage running these for Evaluations (and later for Monitoring!)\n",
        "\n",
        "Alternatively you can define AI, Code and Human based Evaluators via the UI - see the relevant `How-to guides` on [Evaluations](https://humanloop.com/docs/v5/evaluation/overview) for creating Evaluators of different kinds.\n",
        "\n",
        "Further you can choose to not host the Evaluator on Humanloop and instead use your own runtime and instead post the results as part of the Evaluation. This can be useful for more complex workflows that require custom dependencies or resources, but lies outside the scope of this tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0dcb9069",
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_evaluators():\n",
        "    for evaluator_name, return_type in [\n",
        "        (\"exact_match\", \"boolean\"),\n",
        "        (\"levenshtein\", \"number\"),\n",
        "    ]:\n",
        "        with open(f\"../../assets/evaluators/{evaluator_name}.py\", \"r\") as f:\n",
        "            code = f.read()\n",
        "\n",
        "        requests.post(\n",
        "            f\"{HOST}/v5/evaluators\",\n",
        "            json={\n",
        "                \"path\": f\"evals_demo/{evaluator_name}\",\n",
        "                \"spec\": {\n",
        "                    \"evaluator_type\": \"python\",\n",
        "                    \"arguments_type\": \"target_required\",\n",
        "                    \"return_type\": return_type,\n",
        "                    \"code\": code,\n",
        "                },\n",
        "                \"commit_message\": f\"New version from {evaluator_name}.py\",\n",
        "            },\n",
        "            headers={\"Content-Type\": \"application/json\", \"X-API-Key\": HL_KEY},\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8138e15d",
      "metadata": {},
      "outputs": [],
      "source": [
        "upload_evaluators()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b48f645",
      "metadata": {},
      "source": [
        "## Run Evaluation\n",
        "\n",
        "Now we can start to trigger Evaluations on Humanloop using our Dataset and Evaluators:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "12405c95",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation created: evr_B7RELNW5C3VoCRuGCPRoh\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Create the Evaluation specifying the Dataset and Evaluators to use\n",
        "response = requests.post(\n",
        "    f\"{HOST}/v5/evaluations\",\n",
        "    json={\n",
        "        \"dataset\": {\"path\": \"evals_demo/medqa-test\"},\n",
        "        \"evaluators\": [\n",
        "            {\"path\": \"evals_demo/exact_match\"},\n",
        "            {\"path\": \"evals_demo/levenshtein\"},\n",
        "        ],\n",
        "    },\n",
        "    headers={\"X-API-KEY\": HL_KEY},\n",
        ")\n",
        "evaluation_id = response.json()[\"id\"]\n",
        "print(f\"Evaluation created: {evaluation_id}\")\n",
        "\n",
        "\n",
        "def populate_evaluation():\n",
        "    \"\"\"Run a variation of your Pipeline over the Dataset to populate results\"\"\"\n",
        "    datapoints_response = requests.get(\n",
        "        f\"{HOST}/v5/datasets/{dataset_id}?include_datapoints=true\",\n",
        "        headers={\"X-API-KEY\": HL_KEY},\n",
        "    ).json()\n",
        "    for datapoint in tqdm(datapoints_response[\"datapoints\"]):\n",
        "        ask_question(\n",
        "            inputs=datapoint[\"inputs\"],\n",
        "            datapoint_id=datapoint[\"id\"],\n",
        "            evaluation_id=evaluation_id,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c951317c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': '4b1ead72e474486180337bc3bbb68900', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:11<03:38, 11.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '45599725d68941139496993ba14d0bcd', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:22<03:21, 11.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'e3c7c753c45c401596bd91a62d162338', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:34<03:13, 11.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'c3ce3094582742618e9f4ea5c5deb158', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:43<02:49, 10.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '4aa1806f2e3646338642555ff986ee3a', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:54<02:41, 10.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'd5b15d2b7f1a420e848971c457c6eaa0', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [01:08<02:43, 11.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'd6f076d4a41f43dfb6f729067823dab6', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [01:17<02:22, 10.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'd4c614a80a694708a804f96520ff076a', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [01:32<02:26, 12.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'b0f1a08f4e4a41189d2a7a0f5facd30f', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [01:41<02:05, 11.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '5a09d0c2767f4da487ea41695b289f6a', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [01:51<01:49, 10.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '95a59037cb0b48feaec69f9a38e12228', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [02:01<01:35, 10.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '4ce8d30e24a649f1a144d50d4acd5935', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [02:12<01:25, 10.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'de41e03a15e24b6fb310f886f823e431', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [02:22<01:12, 10.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '9b627e74b407458da4c65a24b634d39e', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [02:32<01:01, 10.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '06fd059892c34245b10b921a2be189ad', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [02:41<00:49,  9.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '033a05f1f45842e6a591310c84ec8287', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [02:51<00:39,  9.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '0563a08c195c43aea85d256ce6ac5920', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [03:02<00:31, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': '15967e5f21e64128a75913edc3b02625', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [03:12<00:20, 10.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'cb508789c613464b9e52e16b1f0c7ce1', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [03:24<00:10, 10.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n",
            "{'id': 'd224e7af34b34b2eadc0062bc17b2303', 'flow_id': 'fl_MndWfGWogEIMKCDaISagx', 'version_id': 'flv_Nu0O5GMl49i5YxuEJaPlK', 'trace_status': 'incomplete'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [03:35<00:00, 10.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTPConnectionPool(host='0.0.0.0', port=80): Read timed out. (read timeout=2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "populate_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "426e8c98",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a21dcd8b",
      "metadata": {},
      "source": [
        "Mark Traces as complete so evaluation can run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4dd1e7b7e542c45",
      "metadata": {},
      "source": [
        "## Get Results and URL\n",
        "\n",
        "We can not get the aggregate results via the API and the URL to navigate to the Evaluation in the Humanloop UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e22e0558dc082de6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL:  http://0.0.0.0:80/v5/evaluations/evr_B7RELNW5C3VoCRuGCPRoh\n"
          ]
        }
      ],
      "source": [
        "evaluation_response = requests.get(\n",
        "    f\"{HOST}/v5/evaluations/{evaluation_id}\",\n",
        "    headers={\"X-API-KEY\": HL_KEY},\n",
        ")\n",
        "print(\"URL: \", evaluation_response.url)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
