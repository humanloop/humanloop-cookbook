{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Files declared in code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial highlights how to combine Humanloop decorated files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting up imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from humanloop import Humanloop\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "from levenshtein import compare_log_and_target\n",
    "from exact_match import exact_match\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiating the Humanloop client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanloop = Humanloop(api_key=os.getenv(\"HUMANLOOP_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiating the vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = chromadb.chromadb.Client()\n",
    "collection = chroma.get_or_create_collection(name=\"MedQA\")\n",
    "\n",
    "# init collection into which we will add documents\n",
    "knowledge_base = pd.read_parquet(\"../../../assets/sources/textbooks.parquet\")\n",
    "knowledge_base = knowledge_base.sample(5, random_state=42)\n",
    "collection.add(\n",
    "    documents=knowledge_base[\"contents\"].to_list(),\n",
    "    ids=knowledge_base[\"id\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading the evaluation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints_df = pd.read_json(\"../../../assets/datapoints.jsonl\", lines=True)\n",
    "datapoints = [row.to_dict() for _, row in datapoints_df.iterrows()][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Declare Humanloop Files via code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"Answer the following question factually.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Options:\n",
    "- {option_A}\n",
    "- {option_B}\n",
    "- {option_C}\n",
    "- {option_D}\n",
    "- {option_E}\n",
    "\n",
    "---\n",
    "\n",
    "Here is some retrieved information that might be helpful.\n",
    "Retrieved data:\n",
    "{retrieved_data}\n",
    "\n",
    "---\n",
    "\n",
    "Give you answer in 3 sections using the following format. Do not include the quotes or the brackets. Do include the \"---\" separators.\n",
    "```\n",
    "<chosen option verbatim>\n",
    "---\n",
    "<clear explanation of why the option is correct and why the other options are incorrect. keep it ELI5.>\n",
    "---\n",
    "<quote relevant information snippets from the retrieved data verbatim. every line here should be directly copied from the retrieved data>\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def retrieval_tool(question: str) -> str:\n",
    "    \"\"\"Retrieve most relevant document from the vector db (Chroma) for the question.\"\"\"\n",
    "    response = collection.query(query_texts=[question], n_results=1)\n",
    "    retrieved_doc = response[\"documents\"][0][0]\n",
    "    return retrieved_doc\n",
    "\n",
    "\n",
    "def ask_model(\n",
    "    question: str,\n",
    "    option_A: str,\n",
    "    option_B: str,\n",
    "    option_C: str,\n",
    "    option_D: str,\n",
    "    option_E: str,\n",
    ") -> str:\n",
    "    \"\"\"Ask a question and get an answer using a simple RAG pipeline\"\"\"\n",
    "    openai = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"))\n",
    "\n",
    "    # Retrieve context\n",
    "    retrieved_data = retrieval_tool(question)\n",
    "    inputs = {\n",
    "        \"question\": question,\n",
    "        \"option_A\": option_A,\n",
    "        \"option_B\": option_B,\n",
    "        \"option_C\": option_C,\n",
    "        \"option_D\": option_D,\n",
    "        \"option_E\": option_E,\n",
    "        \"retrieved_data\": retrieved_data,\n",
    "    }\n",
    "\n",
    "    # Populate the Prompt template\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": TEMPLATE.format(**inputs),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call OpenAI to get response\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def entrypoint(\n",
    "    question: str,\n",
    "    option_A: str,\n",
    "    option_B: str,\n",
    "    option_C: str,\n",
    "    option_D: str,\n",
    "    option_E: str,\n",
    "):\n",
    "    output = ask_model(\n",
    "        question=question,\n",
    "        option_A=option_A,\n",
    "        option_B=option_B,\n",
    "        option_C=option_C,\n",
    "        option_D=option_D,\n",
    "        option_E=option_E,\n",
    "    )\n",
    "    humanloop.flows.log(\n",
    "        path=\"Evaluations SDK Demo/MedQA Answer Flow 8\",\n",
    "        flow={\n",
    "            \"attributes\": {\n",
    "                \"prompt\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"environment\": \"evaluation\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        inputs={\n",
    "            \"question\": question,\n",
    "            \"option_A\": option_A,\n",
    "            \"option_B\": option_B,\n",
    "            \"option_C\": option_C,\n",
    "            \"option_D\": option_D,\n",
    "            \"option_E\": option_E,\n",
    "        },\n",
    "        output=json.dumps({\"answer\": output}),\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[96mEvaluating your flow function corresponding to `Evaluations SDK Demo/MedQA Answer Flow 8` on Humanloop\u001b[0m \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "status_code: 500, body: {'detail': 'Internal server error'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhumanloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluations SDK Demo/MedQA Answer Flow 8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattributes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menvironment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMedQA Evaluation Decorators Debug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatapoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatapoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluations SDK Demo/Dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluations SDK Demo/Levenshtein\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_required\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompare_log_and_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluations SDK Demo/Exact Match\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_required\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboolean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/humanloop-python/src/humanloop/client.py:71\u001b[0m, in \u001b[0;36mExtendedEvalsClient.run\u001b[0;34m(self, file, name, dataset, evaluators, workers)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed Humanloop client defined to run evals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_context_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_context_variable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/humanloop-python/src/humanloop/eval_utils/run.py:316\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(client, file, name, dataset, evaluation_context_variable, evaluators, workers)\u001b[0m\n\u001b[1;32m    314\u001b[0m         flow_version \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m: version}\n\u001b[1;32m    315\u001b[0m         file_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfile_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflow_version}\n\u001b[0;32m--> 316\u001b[0m     hl_file \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfile_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/humanloop-python/src/humanloop/flows/client.py:679\u001b[0m, in \u001b[0;36mFlowsClient.upsert\u001b[0;34m(self, attributes, path, id, commit_message, request_options)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m--> 679\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[0;31mApiError\u001b[0m: status_code: 500, body: {'detail': 'Internal server error'}"
     ]
    }
   ],
   "source": [
    "humanloop.evaluations.run(\n",
    "    file={\n",
    "        \"path\": \"Evaluations SDK Demo/MedQA Answer Flow 8\",\n",
    "        \"callable\": entrypoint,\n",
    "        \"version\": {\n",
    "            \"attributes\": {\n",
    "                \"prompt\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"environment\": \"evaluation\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"type\": \"flow\",\n",
    "    },\n",
    "    name=\"MedQA Evaluation Decorators Debug\",\n",
    "    dataset={\n",
    "        \"datapoints\": datapoints,\n",
    "        \"path\": \"Evaluations SDK Demo/Dataset\",\n",
    "    },\n",
    "    evaluators=[\n",
    "        {\n",
    "            \"path\": \"Evaluations SDK Demo/Levenshtein\",\n",
    "            \"args_type\": \"target_required\",\n",
    "            \"return_type\": \"number\",\n",
    "            \"callable\": compare_log_and_target,\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"Evaluations SDK Demo/Exact Match\",\n",
    "            \"args_type\": \"target_required\",\n",
    "            \"return_type\": \"boolean\",\n",
    "            \"callable\": exact_match,\n",
    "        },\n",
    "    ],\n",
    "    workers=8,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanloop-cookbook-XVtM0WJo-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
